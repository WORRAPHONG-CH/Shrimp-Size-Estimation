{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics \n",
    "from ultralytics import YOLO\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.166  Python-3.9.17 torch-2.0.1 CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO\\test\\cam2_water-surface_10.08.2023_15.14-PascalVOC-export\\JPEGImages.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:08<00:00,  1.77s/it]\n",
      "                   all         66       1166      0.836      0.895      0.939      0.586\n",
      "Speed: 0.9ms preprocess, 56.8ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C200A46F70>\n",
      "fitness: 0.6217693070606644\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([     0.5865])\n",
      "names: {0: 'Shrimp'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.8358623053483298, 'metrics/recall(B)': 0.8953687821612349, 'metrics/mAP50(B)': 0.9392353238666286, 'metrics/mAP50-95(B)': 0.586495305193335, 'fitness': 0.6217693070606644}\n",
      "save_dir: WindowsPath('runs/detect/val')\n",
      "speed: {'preprocess': 0.9034041202429569, 'inference': 56.75707441387755, 'loss': 0.0, 'postprocess': 0.6364186604817709}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate yolo_n1 (SET1-4)\n",
    "# Load a model\n",
    "path_data = \"../CODE/data_custom.yaml\"\n",
    "path_best = \"../result_yolo/yolo_n1/weights/best.pt\"\n",
    "model = YOLO(path_best)  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(mode='test',data=path_data,imgsz=640,batch=16,split=\"test\")  \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.166  Python-3.9.17 torch-2.0.1 CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO\\test\\cam2_water-surface_10.08.2023_15.14-PascalVOC-export\\JPEGImages.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:08<00:00,  1.73s/it]\n",
      "                   all         66       1166      0.864      0.893      0.949      0.596\n",
      "Speed: 0.9ms preprocess, 55.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C25F968220>\n",
      "fitness: 0.6315050412549692\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.59626])\n",
      "names: {0: 'Shrimp'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.8639665727276582, 'metrics/recall(B)': 0.8932986575169158, 'metrics/mAP50(B)': 0.9487389760321266, 'metrics/mAP50-95(B)': 0.5962568262797295, 'fitness': 0.6315050412549692}\n",
      "save_dir: WindowsPath('runs/detect/val2')\n",
      "speed: {'preprocess': 0.9074211120605469, 'inference': 55.13775709903601, 'loss': 0.0, 'postprocess': 0.4999854347922585}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate yolo_n2 (SET1-7)\n",
    "# Load a model\n",
    "\n",
    "path_data = \"../CODE/data_custom.yaml\"\n",
    "path_best = \"../result_yolo/yolo_n2/weights/best.pt\"\n",
    "model = YOLO(path_best)  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(mode='test',data=path_data,imgsz=640,batch=16,split=\"test\")  \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.166  Python-3.9.17 torch-2.0.1 CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO2\\test\\cam2_water-surface_22.08.2023-15.34-PascalVOC-export\\JPEGImages... 38 images, 0 backgrounds, 0 corrupt: 100%|██████████| 38/38 [00:00<00:00, 503.26it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO2\\test\\cam2_water-surface_22.08.2023-15.34-PascalVOC-export\\JPEGImages.cache\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<00:00,  1.71s/it]\n",
      "                   all         38        626      0.791      0.856      0.901      0.514\n",
      "Speed: 0.8ms preprocess, 59.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C20293CEB0>\n",
      "fitness: 0.5524514631191897\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([     0.5137])\n",
      "names: {0: 'Shrimp'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.7912793879787463, 'metrics/recall(B)': 0.8562300319488818, 'metrics/mAP50(B)': 0.9012075986682078, 'metrics/mAP50-95(B)': 0.513700781391521, 'fitness': 0.5524514631191897}\n",
      "save_dir: WindowsPath('runs/detect/val5')\n",
      "speed: {'preprocess': 0.79056463743511, 'inference': 59.59772436242355, 'loss': 0.0, 'postprocess': 0.447317173606471}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate yolo_nSep (SET5-7)\n",
    "# Load a model\n",
    "\n",
    "path_data = \"../CODE/data_custom2.yaml\"\n",
    "path_best = \"../result_yolo/yolo_nSep/weights/best.pt\"\n",
    "model = YOLO(path_best)  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(mode='test',data=path_data,imgsz=640,batch=16,split=\"test\")  \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.166  Python-3.9.17 torch-2.0.1 CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO\\test\\cam2_water-surface_10.08.2023_15.14-PascalVOC-export\\JPEGImages.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:13<00:00,  2.67s/it]\n",
      "                   all         66       1166      0.828      0.907      0.939      0.607\n",
      "Speed: 0.8ms preprocess, 127.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C206732130>\n",
      "fitness: 0.6401662250359867\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([      0.607])\n",
      "names: {0: 'Shrimp'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.8275286953756711, 'metrics/recall(B)': 0.9065180102915952, 'metrics/mAP50(B)': 0.9386331500531213, 'metrics/mAP50-95(B)': 0.6070032333674162, 'fitness': 0.6401662250359867}\n",
      "save_dir: WindowsPath('runs/detect/val6')\n",
      "speed: {'preprocess': 0.8394501426003196, 'inference': 127.21288926673657, 'loss': 0.0, 'postprocess': 0.47215187188350793}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate yolo_s1 (SET1-4)\n",
    "# Load a model\n",
    "\n",
    "path_data = \"../CODE/data_custom.yaml\"\n",
    "path_best = \"../result_yolo/yolo_s1/weights/best.pt\"\n",
    "model = YOLO(path_best)  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(mode='test',data=path_data,imgsz=640,batch=16,split=\"test\")  \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.166  Python-3.9.17 torch-2.0.1 CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO\\test\\cam2_water-surface_10.08.2023_15.14-PascalVOC-export\\JPEGImages.cache... 66 images, 0 backgrounds, 0 corrupt: 100%|██████████| 66/66 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:13<00:00,  2.74s/it]\n",
      "                   all         66       1166      0.848      0.908      0.942      0.608\n",
      "Speed: 0.8ms preprocess, 130.4ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C2067CCC70>\n",
      "fitness: 0.6413021319536215\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.60794])\n",
      "names: {0: 'Shrimp'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.8478678563563349, 'metrics/recall(B)': 0.9081597762532708, 'metrics/mAP50(B)': 0.9415827254739049, 'metrics/mAP50-95(B)': 0.6079376215624789, 'fitness': 0.6413021319536215}\n",
      "save_dir: WindowsPath('runs/detect/val7')\n",
      "speed: {'preprocess': 0.7999015576911696, 'inference': 130.36620616912842, 'loss': 0.0, 'postprocess': 0.5146481774070046}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate yolo_s2 (SET1-7)\n",
    "# Load a model\n",
    "\n",
    "path_data = \"../CODE/data_custom.yaml\"\n",
    "path_best = \"../result_yolo/yolo_s2/weights/best.pt\"\n",
    "model = YOLO(path_best)  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(mode='test',data=path_data,imgsz=640,batch=16,split=\"test\")  \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.166  Python-3.9.17 torch-2.0.1 CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Worra\\Desktop\\Axons\\WORK\\Shrimp Project\\dataset\\YOLO2\\test\\cam2_water-surface_22.08.2023-15.34-PascalVOC-export\\JPEGImages.cache... 38 images, 0 backgrounds, 0 corrupt: 100%|██████████| 38/38 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:07<00:00,  2.59s/it]\n",
      "                   all         38        626      0.814      0.834      0.905      0.539\n",
      "Speed: 0.8ms preprocess, 130.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001C266E5D310>\n",
      "fitness: 0.575806916947457\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.53928])\n",
      "names: {0: 'Shrimp'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.8135074542351617, 'metrics/recall(B)': 0.8338658146964856, 'metrics/mAP50(B)': 0.9045460620476016, 'metrics/mAP50-95(B)': 0.5392803452696632, 'fitness': 0.575806916947457}\n",
      "save_dir: WindowsPath('runs/detect/val8')\n",
      "speed: {'preprocess': 0.7828787753456518, 'inference': 130.90892214524118, 'loss': 0.0, 'postprocess': 0.6061290439806486}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate yolo_sSep (SET5-7)\n",
    "# Load a model\n",
    "\n",
    "path_data = \"../CODE/data_custom2.yaml\"\n",
    "path_best = \"../result_yolo/yolo_sSep/weights/best.pt\"\n",
    "model = YOLO(path_best)  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(mode='test',data=path_data,imgsz=640,batch=16,split=\"test\")  \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
